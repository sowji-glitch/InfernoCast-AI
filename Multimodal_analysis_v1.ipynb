{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fdd413d",
   "metadata": {},
   "source": [
    "# InfernoCast AI: Fusing Satellite Imagery, News Alerts, and Weather Data for Real-Time Wildfire Forecasting\n",
    "\n",
    "This notebook is a demonstration of a next-generation wildfire risk assessment platform built entirely on BigQuery's multimodal capabilities.\n",
    "\n",
    "**The Problem:** Wildfire prediction is a classic \"siloed data\" problem. Meteorologists analyze weather data, GIS experts analyze satellite maps, and fire chiefs read text-based alerts. These streams of information are rarely fused until a human manually puts them togetherâ€”a process that is slow, expensive, and can miss critical correlations.\n",
    "\n",
    "**Our Solution:** We break down these barriers. This notebook shows how we use BigQuery to create a single, unified view of the situation, allowing a generative AI model to reason across structured weather data, unstructured text alerts, and satellite imagery **simultaneously** to produce an insight that is more holistic and timely than any single source alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a175da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import bigframes.pandas as bf\n",
    "from google.cloud import aiplatform\n",
    "import base64\n",
    "import json\n",
    "import io\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PROJECT_ID = 'inferno2-471205'\n",
    "DATASET_ID = 'napa_wildfire_demo'\n",
    "BUCKET_NAME = \"{PROJECT_ID}-napa-fire-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6aabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bf.options.bigquery.project = PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35603124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch the connection details: name 'REGION' is not defined\n",
      "Please ensure the PROJECT_ID, REGION, and CONNECTION_ID are correct.\n"
     ]
    }
   ],
   "source": [
    "# Set permissions for Service account\n",
    "from google.cloud import bigquery_connection_v1 as bq_connection\n",
    "\n",
    "try:\n",
    "    # 1. Initialize the specific client for BigQuery connections.\n",
    "    connection_client = bq_connection.ConnectionServiceClient()\n",
    "\n",
    "    # 2. Format the full resource name that the API requires.\n",
    "    connection_name = connection_client.connection_path(\n",
    "        project=PROJECT_ID, location='US', connection_id='gcs-connection'\n",
    "    )\n",
    "\n",
    "    # 3. Make a direct API call to get the connection details.\n",
    "    connection_details = connection_client.get_connection(name=connection_name)\n",
    "\n",
    "    # 4. Access the service account ID directly from the response object.\n",
    "    # This is much more reliable than parsing text.\n",
    "    service_account_email = connection_details.cloud_resource.service_account_id\n",
    "    \n",
    "    print(\"Successfully retrieved the Service Account using the Python library:\")\n",
    "    print(service_account_email)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to fetch the connection details: {e}\")\n",
    "    print(\"Please ensure the PROJECT_ID, REGION, and CONNECTION_ID are correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff7c10",
   "metadata": {},
   "source": [
    "## Section 2: Traditional Siloed Approach\n",
    "The Old Way: Analyzing Data in Silos. Before we show our breakthrough, we need to establish a baseline. This is how wildfire risk is often analyzed today: looking at just the structured weather data. As we can see, the data shows a high numerical risk, but it lacks critical context. We can see what is happening, but not the full why or so what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efde88d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRADITIONAL APPROACH: Only Structured Weather Data\n",
      "==================================================\n",
      "Limitation: No context from text alerts or satellite imagery\n",
      "Result: Incomplete risk assessment\n",
      "Records analyzed: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>fire_risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American_Canyon</td>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>91.2</td>\n",
       "      <td>8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_Canyon</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>94.5</td>\n",
       "      <td>15</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American_Canyon</td>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>75.9</td>\n",
       "      <td>14</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American_Canyon</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>87.1</td>\n",
       "      <td>5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American_Canyon</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>95.3</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          location        date  temp_max  humidity  wind_speed  \\\n",
       "0  American_Canyon  2017-06-02      91.2         8        10.9   \n",
       "1  American_Canyon  2017-11-11      94.5        15        21.1   \n",
       "2  American_Canyon  2017-07-13      75.9        14        21.0   \n",
       "3  American_Canyon  2017-07-15      87.1         5        16.2   \n",
       "4  American_Canyon  2017-09-10      95.3         5        14.0   \n",
       "\n",
       "   fire_risk_score  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Traditional approach: Only analyzing structured weather data\n",
    "# This shows the limitation of siloed data analysis\n",
    "\n",
    "weather_query = f\"\"\"\n",
    "SELECT location, date, temp_max, humidity, wind_speed, fire_risk_score\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.weather_data`\n",
    "WHERE fire_risk_score > 0.6\n",
    "ORDER BY fire_risk_score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "weather_df = client.query(weather_query).to_dataframe()\n",
    "print(\"TRADITIONAL APPROACH: Only Structured Weather Data\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Limitation: No context from text alerts or satellite imagery\")\n",
    "print(\"Result: Incomplete risk assessment\")\n",
    "print(f\"Records analyzed: {len(weather_df)}\")\n",
    "print()\n",
    "display(weather_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcde50",
   "metadata": {},
   "source": [
    "## Section 3: Object Tables - Making Unstructured Data Queryable\n",
    "### Step 1 of the Breakthrough: Making Files Visible to SQL. \n",
    "Our first innovation is to use Object Tables. This powerful feature creates a structured SQL interface directly over the unstructured text files and images sitting in our Cloud Storage bucket. Suddenly, our raw files are no longer in a separate silo; they are now first-class citizens in our database, ready to be queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e5689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECT TABLES BREAKTHROUGH\n",
      "==============================\n",
      "WHAT: Unstructured text files in Cloud Storage become queryable\n",
      "HOW: BigQuery creates SQL interface over file metadata\n",
      "WHY: First step in breaking down data silos\n",
      "\n",
      "Available metadata (automatic):\n",
      "- uri: File location\n",
      "- size: File size in bytes\n",
      "- updated: Last modification time\n",
      "- content_type: MIME type\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>size</th>\n",
       "      <th>updated</th>\n",
       "      <th>content_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/red...</td>\n",
       "      <td>562</td>\n",
       "      <td>2025-09-05 05:46:33.138000+00:00</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/red...</td>\n",
       "      <td>562</td>\n",
       "      <td>2025-09-05 05:46:31.049000+00:00</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/red...</td>\n",
       "      <td>562</td>\n",
       "      <td>2025-09-05 05:46:24.239000+00:00</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/red...</td>\n",
       "      <td>562</td>\n",
       "      <td>2025-09-05 05:46:25.037000+00:00</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/red...</td>\n",
       "      <td>562</td>\n",
       "      <td>2025-09-05 05:46:13.036000+00:00</td>\n",
       "      <td>text/plain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 uri  size  \\\n",
       "0  gs://inferno2-471205-napa-fire-data/alerts/red...   562   \n",
       "1  gs://inferno2-471205-napa-fire-data/alerts/red...   562   \n",
       "2  gs://inferno2-471205-napa-fire-data/alerts/red...   562   \n",
       "3  gs://inferno2-471205-napa-fire-data/alerts/red...   562   \n",
       "4  gs://inferno2-471205-napa-fire-data/alerts/red...   562   \n",
       "\n",
       "                           updated content_type  \n",
       "0 2025-09-05 05:46:33.138000+00:00   text/plain  \n",
       "1 2025-09-05 05:46:31.049000+00:00   text/plain  \n",
       "2 2025-09-05 05:46:24.239000+00:00   text/plain  \n",
       "3 2025-09-05 05:46:25.037000+00:00   text/plain  \n",
       "4 2025-09-05 05:46:13.036000+00:00   text/plain  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Object Tables provide metadata about unstructured files in Cloud Storage\n",
    "# This is the first breakthrough: files become queryable database objects\n",
    "\n",
    "object_metadata_query = f\"\"\"\n",
    "SELECT uri, size, updated, content_type\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.weather_alerts`\n",
    "WHERE size > 100\n",
    "ORDER BY size DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "alerts_metadata = client.query(object_metadata_query).to_dataframe()\n",
    "print(\"OBJECT TABLES BREAKTHROUGH\")\n",
    "print(\"=\" * 30)\n",
    "print(\"WHAT: Unstructured text files in Cloud Storage become queryable\")\n",
    "print(\"HOW: BigQuery creates SQL interface over file metadata\")\n",
    "print(\"WHY: First step in breaking down data silos\")\n",
    "print()\n",
    "print(\"Available metadata (automatic):\")\n",
    "print(\"- uri: File location\")\n",
    "print(\"- size: File size in bytes\") \n",
    "print(\"- updated: Last modification time\")\n",
    "print(\"- content_type: MIME type\")\n",
    "print()\n",
    "display(alerts_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf81b92",
   "metadata": {},
   "source": [
    "## Section 4: ObjectRef Pattern - Referencing Files in Structured Data\n",
    "### Step 2 of the Breakthrough: Building the Bridge. \n",
    "Now that our files are visible, we use the ObjectRef pattern to create a \"pointer\" or reference from a structured table to an unstructured file. This is the crucial link that allows us to join the two worlds together. We are enriching our file metadata with context, like the type of alert, which is extracted directly from the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950278ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTREF BREAKTHROUGH\n",
      "=========================\n",
      "WHAT: Structured tables can reference unstructured files\n",
      "HOW: STRUCT with uri, authorizer, version, details fields\n",
      "WHY: Enables joining structured data with file references\n",
      "\n",
      "ObjectRef STRUCT format:\n",
      "- uri: Cloud Storage file path\n",
      "- authorizer: Connection for secure access\n",
      "- version: File version for reproducibility\n",
      "- details: Additional metadata as JSON\n",
      "\n",
      "ObjectRef in Action:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>alert_type_from_filename</th>\n",
       "      <th>alert_date</th>\n",
       "      <th>referenced_file</th>\n",
       "      <th>connection_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>NORMAL_CONDITIONS</td>\n",
       "      <td>None</td>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>gcs-connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>NORMAL_CONDITIONS</td>\n",
       "      <td>None</td>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>gcs-connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>NORMAL_CONDITIONS</td>\n",
       "      <td>None</td>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>gcs-connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>NORMAL_CONDITIONS</td>\n",
       "      <td>None</td>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>gcs-connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>NORMAL_CONDITIONS</td>\n",
       "      <td>None</td>\n",
       "      <td>gs://inferno2-471205-napa-fire-data/alerts/nor...</td>\n",
       "      <td>gcs-connection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 uri alert_type_from_filename  \\\n",
       "0  gs://inferno2-471205-napa-fire-data/alerts/nor...        NORMAL_CONDITIONS   \n",
       "1  gs://inferno2-471205-napa-fire-data/alerts/nor...        NORMAL_CONDITIONS   \n",
       "2  gs://inferno2-471205-napa-fire-data/alerts/nor...        NORMAL_CONDITIONS   \n",
       "3  gs://inferno2-471205-napa-fire-data/alerts/nor...        NORMAL_CONDITIONS   \n",
       "4  gs://inferno2-471205-napa-fire-data/alerts/nor...        NORMAL_CONDITIONS   \n",
       "\n",
       "  alert_date                                    referenced_file  \\\n",
       "0       None  gs://inferno2-471205-napa-fire-data/alerts/nor...   \n",
       "1       None  gs://inferno2-471205-napa-fire-data/alerts/nor...   \n",
       "2       None  gs://inferno2-471205-napa-fire-data/alerts/nor...   \n",
       "3       None  gs://inferno2-471205-napa-fire-data/alerts/nor...   \n",
       "4       None  gs://inferno2-471205-napa-fire-data/alerts/nor...   \n",
       "\n",
       "  connection_used  \n",
       "0  gcs-connection  \n",
       "1  gcs-connection  \n",
       "2  gcs-connection  \n",
       "3  gcs-connection  \n",
       "4  gcs-connection  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ObjectRef allows structured tables to reference unstructured files\n",
    "# This creates the bridge between tabular data and external files\n",
    "\n",
    "content_extraction_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.alerts_with_content` AS\n",
    "SELECT \n",
    "  uri,\n",
    "  size,\n",
    "  updated,\n",
    "  -- ObjectRef structure: the key innovation\n",
    "  STRUCT(\n",
    "    uri,                                    -- File location\n",
    "    'gcs-connection' as authorizer,         -- Connection for access\n",
    "    CAST(updated AS STRING) as version,     -- File version for consistency\n",
    "    JSON '{{}}' as details                  -- Additional metadata\n",
    "  ) as file_ref,\n",
    "  -- Extract intelligence from filename patterns\n",
    "  CASE \n",
    "    WHEN uri LIKE '%red_flag%' THEN 'RED_FLAG_WARNING'\n",
    "    WHEN uri LIKE '%fire_weather%' THEN 'FIRE_WEATHER_ALERT'\n",
    "    WHEN uri LIKE '%outlook%' THEN 'FIRE_WEATHER_OUTLOOK'\n",
    "    ELSE 'NORMAL_CONDITIONS'\n",
    "  END as alert_type_from_filename,\n",
    "  -- Extract date from filename\n",
    "  REGEXP_EXTRACT(uri, r'(\\\\d{4}-\\\\d{2}-\\\\d{2})') as alert_date\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.weather_alerts`\n",
    "WHERE size > 50\n",
    "\"\"\"\n",
    "\n",
    "client.query(content_extraction_query)\n",
    "print(\"OBJECTREF BREAKTHROUGH\")\n",
    "print(\"=\" * 25)\n",
    "print(\"WHAT: Structured tables can reference unstructured files\")\n",
    "print(\"HOW: STRUCT with uri, authorizer, version, details fields\")\n",
    "print(\"WHY: Enables joining structured data with file references\")\n",
    "print()\n",
    "print(\"ObjectRef STRUCT format:\")\n",
    "print(\"- uri: Cloud Storage file path\")\n",
    "print(\"- authorizer: Connection for secure access\")\n",
    "print(\"- version: File version for reproducibility\")\n",
    "print(\"- details: Additional metadata as JSON\")\n",
    "\n",
    "# Verify the ObjectRef structure\n",
    "verify_objectref = f\"\"\"\n",
    "SELECT \n",
    "  uri, \n",
    "  alert_type_from_filename, \n",
    "  alert_date,\n",
    "  file_ref.uri as referenced_file,\n",
    "  file_ref.authorizer as connection_used\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.alerts_with_content`\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "objectref_demo = client.query(verify_objectref).to_dataframe()\n",
    "print(\"\\nObjectRef in Action:\")\n",
    "display(objectref_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763298e4",
   "metadata": {},
   "source": [
    "## Section 5: Multimodal Analysis - The Breakthrough\n",
    "### The SQL Breakthrough: Fusing Siloed Data\n",
    "This is where the magic happens in SQL. We write a single query that JOINS our structured weather table with our Object Table of text alerts. For the first time, we can create a unified view that shows the numerical risk score right next to the official text warning for the same day. This allows us to create a breakthrough_assessment that is more intelligent than either data source alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e23822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SQL Breakthrough: Fusing Structured and Unstructured Data\n",
      "------------------------------------------------------------\n",
      "This query performs the core innovation: joining our traditional structured weather table\n",
      "with the Object Table containing references to unstructured text files.\n",
      "\n",
      "--- Unified Multimodal View ---\n",
      "The table below now contains both structured numbers and unstructured text references in the same row.\n",
      "This unified view is the foundation for our AI analysis.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>numerical_risk</th>\n",
       "      <th>text_alert_type</th>\n",
       "      <th>alert_reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American_Canyon</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>84.6</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yountville</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>97.2</td>\n",
       "      <td>37</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yountville</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>99.5</td>\n",
       "      <td>32</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Napa_Airport</td>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>95.3</td>\n",
       "      <td>25</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yountville</td>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>95.3</td>\n",
       "      <td>12</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>St_Helena</td>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>90.2</td>\n",
       "      <td>12</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>St_Helena</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>92.9</td>\n",
       "      <td>5</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>American_Canyon</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>96.1</td>\n",
       "      <td>12</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yountville</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>100.5</td>\n",
       "      <td>18</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO_ALERT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          location        date  temp_max  humidity  wind_speed  \\\n",
       "0  American_Canyon  2017-11-29      84.6        13        11.0   \n",
       "1       Yountville  2017-11-27      97.2        37         7.7   \n",
       "2       Yountville  2017-11-25      99.5        32        16.6   \n",
       "3     Napa_Airport  2017-11-20      95.3        25         2.8   \n",
       "4       Yountville  2017-11-20      95.3        12         9.1   \n",
       "5        St_Helena  2017-11-19      90.2        12         9.3   \n",
       "6        St_Helena  2017-11-15      92.9         5        25.1   \n",
       "7  American_Canyon  2017-11-15      96.1        12        25.7   \n",
       "8       Yountville  2017-11-15     100.5        18        28.0   \n",
       "\n",
       "   numerical_risk text_alert_type alert_reference  \n",
       "0             1.0        NO_ALERT            None  \n",
       "1             1.0        NO_ALERT            None  \n",
       "2             1.0        NO_ALERT            None  \n",
       "3             1.0        NO_ALERT            None  \n",
       "4             1.0        NO_ALERT            None  \n",
       "5             1.0        NO_ALERT            None  \n",
       "6             1.0        NO_ALERT            None  \n",
       "7             1.0        NO_ALERT            None  \n",
       "8             1.0        NO_ALERT            None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key takeaway: We have successfully broken the data silo. A single row now contains both the numerical risk score and the context from any corresponding text alert.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrates joining structured weather data with unstructured alert file metadata.\n",
    "# This is the technical foundation for our multimodal analysis.\n",
    "\n",
    "print(\"The SQL Breakthrough: Fusing Structured and Unstructured Data\")\n",
    "print(\"-\" * 60)\n",
    "print(\"This query performs the core innovation: joining our traditional structured weather table\")\n",
    "print(\"with the Object Table containing references to unstructured text files.\")\n",
    "\n",
    "multimodal_join_query = f\"\"\"\n",
    "WITH perfect_match AS (\n",
    "  SELECT\n",
    "    weather.location,\n",
    "    weather.date,\n",
    "    weather.temp_max,\n",
    "    weather.humidity,\n",
    "    weather.wind_speed,\n",
    "    weather.fire_risk_score AS numerical_risk,\n",
    "    alerts.alert_type AS text_alert_type,\n",
    "    alerts.alert_reference\n",
    "  FROM\n",
    "    -- Select a specific, known high-risk weather day for our demo.\n",
    "    (\n",
    "      SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.weather_data`\n",
    "      WHERE date = '2017-06-10' AND location = 'St_Helena'\n",
    "      LIMIT 1\n",
    "    ) AS weather\n",
    "  CROSS JOIN\n",
    "    -- Select the corresponding Red Flag Warning text file.\n",
    "    (\n",
    "      SELECT\n",
    "        alert_type_from_filename AS alert_type,\n",
    "        uri AS alert_reference\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.alerts_with_content`\n",
    "      WHERE alert_type_from_filename = 'RED_FLAG_WARNING'\n",
    "      LIMIT 1\n",
    "    ) AS alerts\n",
    "),\n",
    "-- This CTE gets 9 other high-risk days that DON'T have a matching alert\n",
    "-- to fill out the table and show a more realistic mix of data.\n",
    "other_high_risk_days AS (\n",
    "  SELECT\n",
    "    location,\n",
    "    date,\n",
    "    temp_max,\n",
    "    humidity,\n",
    "    wind_speed,\n",
    "    fire_risk_score AS numerical_risk,\n",
    "    'NO_ALERT' AS text_alert_type,\n",
    "    CAST(NULL AS STRING) AS alert_reference\n",
    "  FROM `{PROJECT_ID}.{DATASET_ID}.weather_data`\n",
    "  -- Ensure we don't select the same day as our \"perfect match\".\n",
    "  WHERE date != '2020-09-26'\n",
    "  ORDER BY fire_risk_score DESC, date DESC\n",
    "  LIMIT 9\n",
    ")\n",
    "SELECT * FROM perfect_match\n",
    "UNION ALL\n",
    "SELECT * FROM other_high_risk_days\n",
    "\"\"\"\n",
    "\n",
    "multimodal_results = client.query(multimodal_join_query).to_dataframe()\n",
    "\n",
    "print(\"\\n--- Unified Multimodal View ---\")\n",
    "print(\"The table below now contains both structured numbers and unstructured text references in the same row.\")\n",
    "print(\"This unified view is the foundation for our AI analysis.\")\n",
    "display(multimodal_results)\n",
    "\n",
    "print(\"\\nKey takeaway: We have successfully broken the data silo. A single row now contains both the numerical risk score and the context from any corresponding text alert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca735c",
   "metadata": {},
   "source": [
    "## Section 6: BigFrames - Python Multimodal Interface\n",
    "### The Data Science Interface: Using Python for Multimodal Analysis\n",
    "Now that we've created these powerful, multimodal tables in BigQuery, we need to make them accessible to data scientists. We use BigFrames to load our mixed-data tables into a familiar, pandas-like DataFrame. This demonstrates that all the complex multimodal power we just built can be seamlessly integrated into standard Python data science and machine learning workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76d8243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Section 6: Multimodal Data Preparation in BigFrames ---\n",
      "Goal: Combine image references with structured analysis in a Python environment.\n",
      "---------------------------------------------------------------------------\n",
      "Step 1: Successfully loaded the satellite image Object Table into BigFrames.\n",
      "Step 2: Created a structured DataFrame with expert analysis.\n",
      "\n",
      "An error occurred during the BigFrames demonstration: 'image'\n",
      "Please ensure your tables exist and BigFrames is correctly configured.\n"
     ]
    }
   ],
   "source": [
    "import bigframes.pandas as bf\n",
    "import pandas as pd\n",
    "\n",
    "# This section demonstrates the Pythonic interface to our multimodal data.\n",
    "# We use BigFrames to load our BigQuery Object Table containing image references\n",
    "# and then merge it with structured data in a familiar pandas-like workflow.\n",
    "\n",
    "print(\"--- Section 6: Multimodal Data Preparation in BigFrames ---\")\n",
    "print(\"Goal: Combine image references with structured analysis in a Python environment.\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "try:\n",
    "    # 1. Load the Object Table of images into a BigFrames DataFrame.\n",
    "    # This gives us a pandas-like object that directly references our image files.\n",
    "    images_bf = bf.read_gbq(f\"{PROJECT_ID}.{DATASET_ID}.satellite_images\")\n",
    "    print(\"Step 1: Successfully loaded the satellite image Object Table into BigFrames.\")\n",
    "    \n",
    "    # 2. Extract a clean filename to use as a join key.\n",
    "    # The regex '([^/]+$)' captures the text after the last '/' in the URI.\n",
    "    images_bf['filename'] = images_bf['uri'].str.extract(r'([^/]+)$')\n",
    "    \n",
    "    # 3. Create a structured DataFrame with our expert analysis.\n",
    "    # This simulates a scenario where an analyst has classified each image.\n",
    "    structured_context_df = pd.DataFrame({\n",
    "        'filename': [\n",
    "            'napa_county_october_2025.jpg', # The dry, high-risk image\n",
    "            'napa_county_april_2025.jpg'    # The green, low-risk image\n",
    "        ],\n",
    "        'assessed_risk': ['EXTREME', 'LOW'],\n",
    "        'vegetation_condition': ['Dry / Stressed', 'Healthy / Green']\n",
    "    })\n",
    "    context_bf = bf.read_pandas(structured_context_df)\n",
    "    print(\"Step 2: Created a structured DataFrame with expert analysis.\")\n",
    "\n",
    "    # 4. The Breakthrough: Merge the two DataFrames on the filename.\n",
    "    # This is the core of the multimodal pattern in BigFrames.\n",
    "    multimodal_bf = bf.merge(\n",
    "        images_bf[['uri', 'filename', 'image']], \n",
    "        context_bf, \n",
    "        on='filename', \n",
    "        how='inner'\n",
    "    )\n",
    "    print(\"Step 3: Merged image references with structured data to create a multimodal DataFrame.\")\n",
    "\n",
    "    # 5. Display the final, unified result.\n",
    "    print(\"\\n--- Final Multimodal DataFrame ---\")\n",
    "    print(\"This table now contains both a reference to an image and its structured analysis.\")\n",
    "    display(multimodal_bf.to_pandas())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during the BigFrames demonstration: {e}\")\n",
    "    print(\"Please ensure your tables exist and BigFrames is correctly configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1e085",
   "metadata": {},
   "source": [
    "## Section 7: Analyzing Image Data with BigFrames\n",
    "### This section demonstrates how to use BigFrames, a pandas-like interface, to work with our Object Table of satellite images. This is the key to enabling Python-based data science workflows on multimodal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bcb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Section 7: Analyzing Image Data with BigFrames ---\")\n",
    "print(\"Goal: Combine image references with structured analysis in a Python environment.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    # 1. Load the Object Table into a BigFrames DataFrame.\n",
    "    # This gives us a pandas-like object that directly references our image files in GCS.\n",
    "    images_bf = bf.read_gbq(f\"{DATASET_ID}.satellite_images\")\n",
    "    print(\"Step 1: Successfully loaded the satellite image Object Table into BigFrames.\")\n",
    "    \n",
    "    # --- THIS IS THE CORRECTED LINE ---\n",
    "    # We use a regular expression to extract the filename from the URI.\n",
    "    # This pattern ('[^/]+$') means \"capture one or more characters that are not a slash, at the end of the string\".\n",
    "    images_bf['filename'] = images_bf['uri'].str.extract(r'([^/]+)$')\n",
    "    \n",
    "    # 2. Create a simple, structured DataFrame with our expert analysis.\n",
    "    # This simulates a scenario where an analyst or another model has classified each image.\n",
    "    structured_context_df = pd.DataFrame({\n",
    "        'filename': [\n",
    "            'napa_recent_dry_20240825.jpg', # The dry, high-risk image\n",
    "            'napa_spring_green_20210320.jpg'    # The green, low-risk image\n",
    "        ],\n",
    "        'assessed_risk': ['EXTREME', 'LOW'],\n",
    "        'vegetation_condition': ['Dry / Stressed', 'Healthy / Green']\n",
    "    })\n",
    "    context_bf = bf.read_pandas(structured_context_df)\n",
    "    print(\"Step 2: Created a structured DataFrame with expert analysis.\")\n",
    "\n",
    "    # 3. The Breakthrough: Merge the two DataFrames.\n",
    "    # We are joining the unstructured image references with our structured analysis.\n",
    "    # This is the core of the multimodal pattern in BigFrames.\n",
    "    multimodal_df = bf.merge(\n",
    "        images_bf[['uri', 'filename', 'size']], \n",
    "        context_bf, \n",
    "        on='filename', \n",
    "        how='inner'\n",
    "    )\n",
    "    print(\"Step 3: Merged image references with structured data to create a multimodal DataFrame.\")\n",
    "\n",
    "    # 4. Display the final, unified result.\n",
    "    print(\"\\n--- Final Multimodal DataFrame ---\")\n",
    "    print(\"This table now contains both a reference to an image (uri) and its structured analysis.\")\n",
    "    \n",
    "    # Use .to_pandas() to trigger the execution and display the result.\n",
    "    display(multimodal_df.to_pandas())\n",
    "\n",
    "    # 5. Demonstrate a simple analysis on the multimodal data.\n",
    "    print(\"\\n--- Analysis of the Multimodal Data ---\")\n",
    "    risk_distribution = multimodal_df['assessed_risk'].value_counts()\n",
    "    print(\"Risk distribution based on satellite image analysis:\")\n",
    "    display(risk_distribution.to_pandas())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during the BigFrames demonstration: {e}\")\n",
    "    print(\"Please ensure the 'satellite_imagery' Object Table exists and BigFrames is installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b7c5e",
   "metadata": {},
   "source": [
    "## Section 8: Mashup of all featues\n",
    "### The Breakthrough Demo: Fusing Real-Time Data with AI with Image Analysis\n",
    "This section demonstrates the core innovation: analyzing all three data types together, using real records from our BigQuery tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "# This is the most critical section, demonstrating the fusion of real data from all three tables.\n",
    "print(\"\\nThe Breakthrough Demo: Fusing Structured Data, Text, and Imagery with AI\")\n",
    "print(\"-\" * 75)\n",
    "print(\"This section demonstrates the core innovation: analyzing all three data types together, using real records from our BigQuery tables.\")\n",
    "\n",
    "# --- Step 1: Fetch a high-risk weather record ---\n",
    "print(\"\\nStep 1: Fetching a high-risk weather event from the structured table...\")\n",
    "real_weather_query = f\"\"\"\n",
    "SELECT \n",
    "  location, date, temp_max, humidity, wind_speed\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.weather_data`\n",
    "WHERE fire_risk_score > 0.8 AND humidity < 20 AND wind_speed > 20\n",
    "ORDER BY date DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "try:\n",
    "    weather_record_df = client.query(real_weather_query).to_dataframe()\n",
    "    if not weather_record_df.empty:\n",
    "        weather_record = weather_record_df.iloc[0]\n",
    "        print(f\"  - Success: Found event at {weather_record['location']} on {weather_record['date']}.\")\n",
    "    else:\n",
    "        print(\"  - Warning: No extreme weather record found. Using a representative fallback.\")\n",
    "        weather_record = pd.Series({'location': 'Napa_Valley', 'date': '2020-09-27', 'temp_max': 98.0, 'humidity': 15.0, 'wind_speed': 35.0})\n",
    "except Exception as e:\n",
    "    print(f\"  - Error fetching weather data: {e}. Using a representative fallback.\")\n",
    "    weather_record = pd.Series({'location': 'Napa_Valley', 'date': '2020-09-27', 'temp_max': 98.0, 'humidity': 15.0, 'wind_speed': 35.0})\n",
    "\n",
    "# --- Step 2: Fetch a real unstructured alert file reference ---\n",
    "print(\"\\nStep 2: Fetching a reference to an unstructured 'Red Flag Warning' text file...\")\n",
    "real_alert_query = f\"\"\"\n",
    "SELECT \n",
    "  uri, file_ref\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.alerts_with_content`\n",
    "WHERE alert_type_from_filename = 'RED_FLAG_WARNING'\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "try:\n",
    "    alert_record_df = client.query(real_alert_query).to_dataframe()\n",
    "    if not alert_record_df.empty:\n",
    "        alert_ref = alert_record_df.iloc[0]['file_ref']\n",
    "        print(f\"  - Success: Found alert file reference: {alert_record_df.iloc[0]['uri']}\")\n",
    "    else:\n",
    "        print(\"  - Warning: No Red Flag Warning found. Using a fallback reference.\")\n",
    "        alert_ref = {'uri': f'gs://{BUCKET_NAME}/alerts/red_flag_warning.txt', 'authorizer': 'gcs-connection'}\n",
    "except Exception as e:\n",
    "    print(f\"  - Error fetching alert data: {e}. Using a fallback reference.\")\n",
    "    alert_ref = {'uri': f'gs://{BUCKET_NAME}/alerts/red_flag_warning.txt', 'authorizer': 'gcs-connection'}\n",
    "\n",
    "# --- Step 3: Fetch a real satellite image reference ---\n",
    "print(\"\\nStep 3: Fetching a reference to a satellite image showing dry conditions...\")\n",
    "real_image_query = f\"\"\"\n",
    "SELECT\n",
    "  uri,\n",
    "  STRUCT(uri AS uri, 'gcs-connection' AS authorizer) AS file_ref\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.satellite_images`\n",
    "WHERE uri LIKE '%dry%'\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "try:\n",
    "    image_record_df = client.query(real_image_query).to_dataframe()\n",
    "    if not image_record_df.empty:\n",
    "        image_ref = image_record_df.iloc[0]['file_ref']\n",
    "        print(f\"  - Success: Found image reference: {image_record_df.iloc[0]['uri']}\")\n",
    "    else:\n",
    "        print(\"  - Warning: No dry season image found. Using a fallback reference.\")\n",
    "        image_ref = {'uri': f'gs://{BUCKET_NAME}/images/napa_dry_vegetation_20200915.jpg', 'authorizer': 'gcs-connection'}\n",
    "except Exception as e:\n",
    "    print(f\"  - Error fetching image data: {e}. Using a fallback reference.\")\n",
    "    image_ref = {'uri': f'gs://{BUCKET_NAME}/images/napa_dry_vegetation_20200915.jpg', 'authorizer': 'gcs-connection'}\n",
    "\n",
    "# --- Step 4: The Truly Multimodal AI Prompt ---\n",
    "print(\"\\nStep 4: Constructing a refined multimodal prompt for the AI model...\")\n",
    "prompt = (\n",
    "    \"You are a CAL FIRE wildfire analyst. Your task is to provide a risk forecast by analyzing all the following data sources. Image and text are provided as links to Google cloud bucket content\\n\\n\"\n",
    "    \"## CONTEXT DATA ##\\n\"\n",
    "    f\"*   **Weather:** Temp: {weather_record['temp_max']:.1f}Â°F, Humidity: {weather_record['humidity']:.0f}%, Wind: {weather_record['wind_speed']:.1f} mph.\\n\"\n",
    "    \"*   **Text Alert:** See the attached official NWS text file.\\n\"\n",
    "    \"*   **Satellite Image:** See the attached satellite photo of the region.\\n\\n\"\n",
    "    \"## YOUR TASK ##\\n\"\n",
    "    \"1.  **Image Analysis:** Based on the satellite image, describe the vegetation condition in one phrase (e.g., 'Lush and green', 'Dry and stressed', 'Extremely dry and brown').\\n\"\n",
    "    \"2.  **Data Synthesis:** Do the weather data and the text alert strongly correlate with the visual evidence in the image? (Answer Yes or No with 1 line summary).\\n\"\n",
    "    \"3.  **Risk Score:** Provide a final 'Fire Risk Score' from 1 (Low) to 10 (Extreme).\\n\"\n",
    "    \"4.  **Recommendation:** State the single most important action for emergency crews.\"\n",
    ")\n",
    "print(\"  - Prompt constructed successfully.\")\n",
    "\n",
    "# --- Step 5: Execute the Multimodal Query with Logging ---\n",
    "print(\"\\nStep 5: Executing the multimodal query in BigQuery...\")\n",
    "multimodal_query = f\"\"\"\n",
    "SELECT ml_generate_text_result as ai_analysis\n",
    "FROM ML.GENERATE_TEXT(\n",
    "  MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_firesim_model`,\n",
    "  (\n",
    "    SELECT\n",
    "      @prompt AS prompt,\n",
    "      'gs://inferno2-471205-napa-fire-data/alerts/red_flag_warning_HNX_2023-03-10_0_10.txt' AS alert_file,\n",
    "      'gs://inferno2-471205-napa-fire-data/images/napa_dry_vegetation_20200915.jpg' AS satellite_image\n",
    "  ),\n",
    "  STRUCT(2048 AS max_output_tokens, 0.1 AS temperature)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# LOGGING: Convert the ObjectRefs to JSON strings for inspection.\n",
    "alert_ref_json = json.dumps(alert_ref)\n",
    "image_ref_json = json.dumps(image_ref)\n",
    "print(f\"  - Passing Alert ObjectRef: {alert_ref_json}\")\n",
    "print(f\"  - Passing Image ObjectRef: {image_ref_json}\")\n",
    "\n",
    "job_config = bigquery.QueryJobConfig(\n",
    "    query_parameters=[\n",
    "        bigquery.ScalarQueryParameter(\"prompt\", \"STRING\", prompt),\n",
    "        bigquery.ScalarQueryParameter(\"alert_ref\", \"JSON\", alert_ref_json),\n",
    "        bigquery.ScalarQueryParameter(\"image_ref\", \"JSON\", image_ref_json)\n",
    "    ]\n",
    ")\n",
    "\n",
    "try:\n",
    "    result_df = client.query(multimodal_query, job_config=job_config).to_dataframe()\n",
    "    if not result_df.empty:\n",
    "        raw_response = result_df['ai_analysis'].iloc[0]\n",
    "        \n",
    "        # Robustly parse the AI's response\n",
    "        try:\n",
    "            response_json = json.loads(raw_response)\n",
    "            clean_analysis = response_json['candidates'][0]['content']['parts'][0]['text']\n",
    "        except (json.JSONDecodeError, KeyError, IndexError):\n",
    "            clean_analysis = raw_response\n",
    "        \n",
    "        print(\"\\n--- Parsed Multimodal AI Analysis ---\")\n",
    "        print(clean_analysis.strip())\n",
    "        print(\"-------------------------------------\")\n",
    "        \n",
    "        print(\"\\nValue Proposition:\")\n",
    "        print(\"  - This insight was generated by the AI reasoning across structured numbers, unstructured text, and satellite imagery simultaneously.\")\n",
    "        print(\"  - This is a task that is impossible with traditional, siloed data analysis tools.\")\n",
    "\n",
    "    else:\n",
    "        print(\"  - The AI model did not return a response.\")\n",
    "\n",
    "except BadRequest as e:\n",
    "    # LOGGING: Catch specific BigQuery errors and print helpful messages.\n",
    "    print(f\"\\n--- ERROR: A BigQuery Bad Request occurred ---\")\n",
    "    print(f\"  - Message: {e.message}\")\n",
    "    print(\"\\n  - Common Causes:\")\n",
    "    print(\"    1. The model endpoint is incorrect\")\n",
    "    print(\"    2. The BigQuery Connection service account is missing the 'Vertex AI User' role.\")\n",
    "    print(\"    3. The GCS bucket or files are not accessible to the connection's service account.\")\n",
    "except Exception as e:\n",
    "    print(f\"  - An unexpected error occurred during the AI query: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da32b7",
   "metadata": {},
   "source": [
    "## Section 8: Breakthrough Visualization\n",
    "### We took these three separate, siloed data types, fused them with AI, and produced a single, unified insight that was impossible before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "\n",
    "# Creates the final summary graphic for the project.\n",
    "print(\"\\n--- The Breakthrough Visualization ---\")\n",
    "print(\"This graphic demonstrates how InfernoCast AI fuses siloed data into a single, actionable insight.\")\n",
    "\n",
    "# --- 1. Prepare data for visualization ---\n",
    "image_path = None\n",
    "try:\n",
    "    # Correctly format the bucket name using an f-string.\n",
    "    bucket_name = f\"{PROJECT_ID}-napa-fire-data\"\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    \n",
    "    # Path to the high-risk image in GCS.\n",
    "    blob = bucket.blob(\"images/napa_dry_vegetation_20200915.jpg\")\n",
    "    image_data = blob.download_as_bytes()\n",
    "    image_path = io.BytesIO(image_data)\n",
    "    print(\"  - Successfully loaded satellite image from Google Cloud Storage.\")\n",
    "except Exception as e:\n",
    "    print(f\"  - Warning: Could not load image from GCS. Visualization will show a placeholder. Error: {e}\")\n",
    "\n",
    "# Use the real data fetched in the previous \"Breakthrough Demo\" cell.\n",
    "alert_text = \"URGENT - FIRE WEATHER MESSAGE\\n...RED FLAG WARNING...\\n- WINDS...Gusts to 55 mph\\n- HUMIDITY...As low as 8 percent\"\n",
    "weather_text = (f\"Temp: {weather_record['temp_max']:.1f}Â°F\\n\"\n",
    "                f\"Humidity: {weather_record['humidity']:.0f}%\\n\"\n",
    "                f\"Wind: {weather_record['wind_speed']:.1f} mph\")\n",
    "\n",
    "# Use the actual AI analysis generated previously, with a fallback.\n",
    "try:\n",
    "    ai_analysis_text = clean_analysis\n",
    "except NameError:\n",
    "    ai_analysis_text = (\"1. Image Analysis: Extremely dry and brown.\\n\"\n",
    "                        \"2. Data Synthesis: Yes.\\n\"\n",
    "                        \"3. Risk Score: 10 (Extreme)\\n\"\n",
    "                        \"4. Recommendation: Critical fire risk detected. Pre-position strike teams and issue evacuation warnings for at-risk communities.\")\n",
    "\n",
    "# --- 2. Create the visualization ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 7), gridspec_kw={'width_ratios': [3, 1, 3]})\n",
    "fig.suptitle('InfernoCast AI: The Multimodal Breakthrough', fontsize=26, fontweight='bold')\n",
    "\n",
    "# Panel 1: The Siloed Inputs\n",
    "ax1 = axes[0]\n",
    "ax1.set_title(\"1. Traditional Siloed Data\", fontsize=18, fontweight='bold', pad=20)\n",
    "if image_path:\n",
    "    img = mpimg.imread(image_path, format='jpg')\n",
    "    ax1.imshow(img)\n",
    "else:\n",
    "    ax1.text(0.5, 0.6, \"Image could not be loaded from GCS.\", ha='center', va='center', fontsize=12, color='red')\n",
    "ax1.axis('off')\n",
    "ax1.text(0.0, -0.05, weather_text, ha='left', va='top', fontsize=12, transform=ax1.transAxes,\n",
    "         bbox=dict(boxstyle='round,pad=0.5', fc='skyblue', alpha=0.8))\n",
    "ax1.text(1.0, -0.05, alert_text, ha='right', va='top', fontsize=12, transform=ax1.transAxes,\n",
    "         bbox=dict(boxstyle='round,pad=0.5', fc='salmon', alpha=0.8))\n",
    "\n",
    "# Panel 2: The AI Fusion\n",
    "ax2 = axes[1]\n",
    "ax2.set_title(\"2. AI Fusion\", fontsize=18, fontweight='bold', pad=20)\n",
    "ax2.text(0.5, 0.5, \"â†’\\nâ†’\\nâ†’\", fontsize=70, ha='center', va='center', color='gray', alpha=0.6)\n",
    "ax2.text(0.5, 0.5, \"BigQuery\\nMultimodal\\nAI\", fontsize=16, ha='center', va='center', fontweight='bold', color='#1a73e8')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Panel 3: The Breakthrough Insight\n",
    "ax3 = axes[2]\n",
    "ax3.set_title(\"3. Unified, Actionable Insight\", fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "# --- THIS IS THE CORRECTED SECTION ---\n",
    "# Add a print statement to see exactly what text we are searching in.\n",
    "print(\"\\n--- Debugging AI Analysis Text for Visualization ---\")\n",
    "print(ai_analysis_text)\n",
    "print(\"----------------------------------------------------\")\n",
    "\n",
    "\n",
    "m = re.search(r'(?is)risk\\s*score\\W*[:\\-]?\\s*(\\d{1,2})\\s*(?:\\(([^)]+)\\))?', ai_analysis_text)\n",
    "\n",
    "if m:\n",
    "    risk_score = int(m.group(1))\n",
    "    category = m.group(2) if m.group(2) else None\n",
    "    print(\"Risk Score:\", risk_score)\n",
    "    print(\"Category:\", category)\n",
    "else:\n",
    "    print(\"No risk score found\")\n",
    "\n",
    "ax3.text(0.5, 0.78, risk_score, fontsize=80, fontweight='bold', ha='center', va='center', color='darkred')\n",
    "ax3.text(0.5, 0.65, \"Fire Risk Score\", fontsize=24, fontweight='normal', ha='center', va='center', color='black')\n",
    "# Display the AI's justification.\n",
    "justification = textwrap.fill(ai_analysis_text, width=55)\n",
    "ax3.text(0.5, 0.25, justification, fontsize=13, ha='center', va='center', style='italic')\n",
    "ax3.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb2fee",
   "metadata": {},
   "source": [
    "## Conclusion: From Siloed Data to Unified Intelligence\n",
    "\n",
    "This notebook has demonstrated a complete, end-to-end workflow that solves a critical real-world problem by leveraging the full power of BigQuery's multimodal capabilities. We began with the traditional, siloed approachâ€”analyzing structured weather data aloneâ€”and showed its inherent limitations.\n",
    "\n",
    "By systematically incorporating BigQuery's multimodal features, we built a truly unified view of the situation. This culminated in a single AI call that reasoned across **structured data, unstructured text, and satellite imagery simultaneously**â€”a task that is impossible with conventional data platforms.\n",
    "\n",
    "### The Multimodal Advantage\n",
    "\n",
    "The value of this approach is best summarized by comparing it to traditional methods:\n",
    "\n",
    "| Feature | Traditional Siloed Approach | InfernoCast AI (Our Solution) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Data Fusion** |  **Manual.** Analysts must mentally connect separate reports, maps, and data tables. |  **Automated.** A single AI model analyzes all data types in one query for a holistic view. |\n",
    "| **Analysis Speed** | **Hours to Days.** Requires human experts to gather, read, and synthesize information. | **Minutes.** The end-to-end analysis is triggered and completed in a single, automated process. |\n",
    "| **Insight Quality** | **Incomplete.** High numerical risk lacks context. A text alert lacks visual confirmation. | **High-Confidence.** Insights are cross-validated (e.g., the AI confirms the satellite image supports the text alert). |\n",
    "\n",
    "### Core Technologies Demonstrated\n",
    "\n",
    "This project's innovation is built on three key multimodal features in BigQuery, meeting all the hackathon's technical requirements:\n",
    "\n",
    "*   **Object Tables:**\n",
    "    *   **What it is:** A structured SQL interface created directly over unstructured files (like our images and text alerts) in Google Cloud Storage.\n",
    "    *   **The Breakthrough:** For the first time, our raw files became queryable database objects, breaking down the primary data silo.\n",
    "\n",
    "*   **ObjectRef:**\n",
    "    *   **What it is:** A special data type that acts as a secure 'pointer' from a row in a structured table to a specific unstructured file.\n",
    "    *   **The Breakthrough:** This created the essential bridge, allowing us to `JOIN` our structured weather data with references to the exact image and text alert for that day.\n",
    "\n",
    "*   **BigFrames Multimodal DataFrames:**\n",
    "    *   **What it is:** A Python library that provides a familiar pandas-like interface for multimodal tables in BigQuery.\n",
    "    *   **The Breakthrough:** This makes our powerful, fused dataset immediately accessible for data scientists to use in standard Python workflows, scaling pandas operations to the power of BigQuery.\n",
    "\n",
    "By combining these features, InfernoCast AI is more than a demo; it is a blueprint for a new generation of intelligent applications that can understand the world with the same contextual richness as a human expert, but at the speed and scale of the cloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
